<!DOCTYPE html>
<html>

<head lang="en">
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>DiVA360: The Dynamic Visual-Audio Dataset for Immersive Neural Fields</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- <base href="/"> -->

    <!--     <link rel="apple-touch-icon" href="apple-touch-icon.png"> -->
    <!-- <link rel="icon" type="image/png" href=""> -->
    <!-- Place favicon.ico in the root directory -->

    <link rel="stylesheet" href="./DiVA/bootstrap.min.css">
    <link rel="stylesheet" href="./DiVA/font-awesome.min.css">
    <link rel="stylesheet" href="./DiVA/codemirror.min.css">
    <link rel="stylesheet" href="./DiVA/app.css">

    <link rel="stylesheet" href="./DiVA/bootstrap.min(1).css">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-E0ZMW34H4P"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());

        gtag('config', 'G-E0ZMW34H4P');
    </script>

    <script src="./DiVA/jquery.min.js"></script>
    <script src="./DiVA/bootstrap.min.js"></script>
    <script src="./DiVA/codemirror.min.js"></script>
    <script src="./DiVA/clipboard.min.js"></script>

    <script src="./DiVA/app.js"></script>
</head>

<body>
    <div class="container" id="main">
        <div class="row">
            <h1 class="col-md-12 text-center">
                DiVA360: The Dynamic Visual-Audio Dataset for Immersive Neural Fields<br>
                <small>
                </small>
            </h1>
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                        Anonymous Authors
                    </li>
                </ul>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2 text-center">
                <ul class="nav nav-pills nav-justified" style="margin-bottom:15px">
                    <li>
                        <a href="./DiVA/2023_DiVA_360_paper.pdf" target=”_blank”>
                            <img src="./DiVA/images/paper.png" height="75px"><br>
                            <h4><strong>Paper</strong></h4>
                        </a>
                    </li>
                    <li>
                        <a href="https://g-6fc7e5.56197.5898.data.globus.org/DiVA-360/dynamic_data.tar" target=”_blank”>
                            <img src="./DiVA/images/data.png" height="75px"><br>
                            <h4><strong>Dynamic Data</strong></h4>
                        </a>
                    </li>
                    <li>
                        <a href="https://g-6fc7e5.56197.5898.data.globus.org/DiVA-360/final-static-dataset.tar.gz"
                            target=”_blank”>
                            <img src="./DiVA/images/data.png" height="75px"><br>
                            <h4><strong>Static Data</strong></h4>
                        </a>
                    </li>
                </ul>
            </div>
            <br>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Video
                </h3>
                <iframe width="100%" style="aspect-ratio: 16 / 9;"
                    src="https://www.youtube.com/embed/26tBmSOXxHo"></iframe>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>

                <img src="./DiVA/images/teaser.png" class="img-responsive" alt="overview"><br>

                <p class="text-justify">
                    Advances in neural fields are enabling high-fidelity capture of the shape and appearance of
                    static
                    and dynamic scenes. However, their capabilities lag behind those offered by representations such
                    as
                    pixels or meshes due to algorithmic challenges and the lack of large-scale real-world datasets.
                    We
                    address the dataset limitation with DiVA-360, a real-world 360&deg <u>d</u>ynam<u>i</u>c
                    <u>v</u>iso-<u>a</u>udio dataset with synchronized multimodal visual, audio, and textual
                    information
                    about table-scale scenes. It contains 46 dynamic scenes, 30 static scenes, and 95 static objects
                    spanning 11 categories captured using a new hardware system using 53 RGB cameras at 120 FPS and
                    6
                    microphones for a total of 8.6M image frames and 1360 s of dynamic data. We provide detailed
                    text
                    descriptions for all scenes, foreground-background segmentation masks, category-specific 3D pose
                    alignment for static objects, as well as metrics for comparison.
                </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Downloading the Data
                </h3>
                <p>
                    We store our dynamic and static dataset on Globus, so to download the data to your local machine, we
                    use Globus Command Line Interface (Globus-CLI) and Globus Connect Personal (GCP). You will first
                    need to install GCP. Follow these instructions depending on your machine:
                <ul>
                    <li><a href="https://docs.globus.org/how-to/globus-connect-personal-mac/" target="_blank">Mac</a>
                    </li>
                    <li><a href="https://docs.globus.org/how-to/globus-connect-personal-windows/"
                            target="_blank">Windows</a></li>
                    <li><a href="https://docs.globus.org/how-to/globus-connect-personal-linux/"
                            target="_blank">Linux</a></li>
                </ul>

                Note: When you are installing GCP, you will have to name your collection/endpoint. You are free to name
                it however you choose, but we suggest naming it "&lt;first name&gt; &lt;last name&gt; personal
                machine". <br>

                Next, you will need to install Globus-CLI and login. Run the following commands: <br>
                <pre>$ pip install globus-cli<br>$ globus login</pre>
                This will take you to a login page. You can either log in through a listed institution,
                through any Google account, or through an ORCID iD. After logging in, you will see a terms of
                service page. To continue, click "Allow". <br>

                To download the data, you will be copying the data from the DiVA360 endpoint to the endpoint you just
                created on your local machine when you installed GCP. First, setup the DiVA360 endpoint:
                <pre>$ diva360_ep=1c8e9e50-d2b6-46cf-a81a-1ce023812799</pre>
                Next, setup your personal endpoint:
                <pre>$ globus endpoint search &lt;collection/endpoint name when setting up GCP&gt;<br>$ personal_ep=&lt;endpoint ID&gt;</pre>

                <b>Important Note: To transfer to your GCP endpoint, the GCP software must be running and connected for
                    the transfer to complete. However, you can close your terminal after the transfer has started. </b>
                <br>

                To transfer the whole dynamic or static dataset, use the following command:
                <pre>$ globus transfer $diva360_ep:/&lt;dynamic or static&gt; $personal_ep:&lt;path to destination&gt;/&lt;dynamic or static&gt; --recursive</pre>

                You can also transfer an individual file or folder from the dataset (note that the "--recursive" flag is
                only needed for folders):
                <pre>$ globus transfer $diva360_ep:&lt;path to file or folder&gt; $personal_ep:&lt;path to destination&gt;/&lt;file or folder name&gt; --recursive</pre>

                You can also transfer multiple files or folders at once using the batch transfer feature. Here is an
                example:
                <pre>$ globus transfer --batch batch_transfer.txt $diva360_ep $personal_ep</pre>
                Assuming you have the following batch_transfer.txt file:
                <pre># to copy a file<br>&lt;path to file&gt; &lt;path to destination&gt;/&lt;file name&gt;<br># to copy a folder<br>&lt;path to folder&gt; &lt;path to destination&gt;/&lt;folder name&gt; --recursive</pre>

                To check the status of your transfer, use the following command:
                <pre>$ globus task show &lt;task ID&gt;</pre>

                </p>

                Here are the details for the dynamic and static dataset structures:
                <details>
                    <summary style="display:list-item">
                        Dynamic Dataset Structure
                    </summary>
                    <ul>
                        <li>
                            |_ assets
                            <ul>
                                <li>|_ all_videos (I-NGP and MixVoxels rendered videos)</li>
                                <li>
                                    |_ calib
                                    <ul>
                                        <li>|_ optim_params.txt(refined camera parameters)</li>
                                        <li>|_ params.txt (unrefined camera parameters)</li>
                                        <li>|_ transforms.json (unrefined camera parameters)</li>
                                        <li>|_ transforms_optim.json (refined camera parameters)</li>
                                    </ul>
                                </li>
                                <li>
                                    |_ objects
                                    <ul>
                                        <li>
                                            |_ &lt;dynamic sequence&gt;
                                            <ul>
                                                <li>
                                                    |_ calib
                                                    <ul>
                                                        <li>|_ transforms.json (refined camera parameters without
                                                            distortion factor)</li>
                                                        <li>|_ transforms_optim.json (refined camera paramters with
                                                            distortion factor)</li>
                                                    </ul>
                                                </li>
                                                <li>
                                                    |_ dynamic_data
                                                    <ul>
                                                        <li>|_ frames_1 (undistored, segmented images of 41 cameras)
                                                        </li>
                                                        <li>
                                                            |_ I-NGP
                                                            <ul>
                                                                <li>|_ test (test view rendering)</li>
                                                                <li>|_ train (per-frame I-NGP weights)</li>
                                                                <li>|_ traj (trajectory rendering)</li>
                                                            </ul>
                                                        </li>
                                                        <li>
                                                            |_ mixvoxels
                                                            <ul>
                                                                <li>
                                                                    |_ &lt;dynamic_sequence_*&gt; (mixvoxels of 150
                                                                    frames)
                                                                    <ul>
                                                                        <li>|_ &lt;dynamic_sequence_*.th&gt; (model
                                                                            checkpoint)</li>
                                                                    </ul>
                                                                </li>
                                                                <li>|_ imgs_hr_spiral_all (spiral trajectory rendering
                                                                    at 2k resolution)
                                                                </li>
                                                                <li>|_ imgs_test_all (test view renderings)</li>
                                                                <li>|_ imgs_test_all_white (test view rendering with
                                                                    white background)</li>
                                                            </ul>
                                                        </li>
                                                        <li>|_ transforms_circle.json (circular rendering trajectory
                                                            parameters)</li>
                                                        <li>|_ transforms_circle_hr.json (circular trajectory parameters
                                                            at 2k resolution_</li>
                                                        <li>|_ transforms_spiral_hr.json (spiral trajectory parameters
                                                            at 2k resolution)</li>
                                                        <li>|_ transforms_test.json (camera parameters of 6 testing
                                                            views)</li>
                                                        <li>|_ transforms_train.json (35 training views)</li>
                                                        <li>|_ transforms_val.json (same as transforms_test.json)</li>
                                                    </ul>
                                                </li>
                                                <li>|_ image (resampled raw data at 30 FPS)</li>
                                                <li>|_ segmented_ngp (segmented, resampled data at 30 FPS)</li>
                                                <li>|_ transforms.json (same as calib/transforms.json)</li>
                                                <li>|_ masks (manual segmentation maps for hourglass, world globe, and
                                                    plasma ball)</li>
                                            </ul>
                                        </li>
                                        <li>...</li>
                                    </ul>
                                </li>
                            </ul>
                        </li>
                        <li>
                            |_ raw_data
                            <ul>
                                <li>|_ synced (synced raw data without audio)</li>
                                <li>|_ syncedaudio (raw data synced with audio)</li>
                            </ul>
                        </li>
                    </ul>
                </details>
                <details>
                    <summary style="display:list-item">
                        Static Dataset Structure
                    </summary>
                    <ul>
                        <li>
                            |_ static-dataset
                            <ul>
                                <li>
                                    |_ &lt;object/scene&gt;
                                    <ul>
                                        <li>
                                            |_ calib
                                            <ul>
                                                <li>|_ params.txt (camera parameters)</li>
                                                <li>|_ to_skip.txt (for some objects/scenes, cameras to skip)</li>
                                            </ul>
                                        </li>
                                        <li>|_ image (raw image data)</li>
                                        <li>|_ refined_segmentation (segmented data)</li>
                                        <li>|_ desciption.json (text description)</li>
                                        <li>
                                            |_ I-NGP
                                            <ul>
                                                <li>|_ train (checkpoint and sigma values for canonicalization)</li>
                                                <li>|_ traj (trajectory renderings)</li>
                                                <li>|_ &lt;object/scene&gt;.csv (evaluation metric results and other
                                                    training information)</li>
                                                <li>|_ mesh.ply (object/scene mesh)</li>
                                            </ul>
                                        </li>
                                    </ul>
                                </li>
                                <li>...</li>
                            </ul>
                        </li>
                        <li>
                            |_ canonical-dataset
                            <ul>
                                <li>
                                    |_ &lt;object category&gt;
                                    <ul>
                                        <li>|_ train (organized training data)</li>
                                        <li>|_ val (organized val data)</li>
                                        <li>|_ data (all data)</li>
                                        <li>|_ &lt;object category&gt;.h5 (to calculate metrics)</li>
                                        <li>
                                            |_ results
                                            <ul>
                                                <li>|_ canonical_rendering (resulting canonical renderings)</li>
                                                <li>|_ checkpoints (model checkpoints)</li>
                                                <li>|_ &lt;object category&gt;.h5 (to calculate metrics)</li>
                                                <li>|_ &lt;object category&gt;_canonical.h5 (to calculate
                                                    canonicalization metrics)</li>
                                                <li>|_ &lt;object category&gt;_rotations.h5 (to calculate rotation
                                                    metrics)</li>
                                            </ul>
                                        </li>
                                    </ul>
                                </li>
                                <li>...</li>
                            </ul>
                        </li>
                    </ul>
                </details>
            </div>
        </div>


        <!-- <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Downloading the Data
                </h3>
                <p>
                    The dynamic dataset is very large, so we currently release just the data and audio (not results).
                    The dynamic data and audio can be directly downloaded using this
                    <a href="https://g-6fc7e5.56197.5898.data.globus.org/DiVA-360/dynamic_data.tar"
                        target="_blank">link</a>.
                    All dynamic sequences can be found in the <span style="font-family:'Courier New'">synced</span>
                    folder, and all corresponding audio files can be found in the <span
                        style="font-family:'Courier New'">syncedaudio</span> folder. Please note that all of the data
                    totals about 750 GB.
                </p>

                <p class="text-justify">
                    The static data, static results, canonical data, and canonical results can be directly downloaded
                    using this
                    <a href="https://g-6fc7e5.56197.5898.data.globus.org/DiVA-360/final-static-dataset.tar.gz"
                        target="_blank">link</a>.
                    All static data can be found in the <span style="font-family:'Courier New'">data</span> folder, and
                    all corresponding results can be found in the <span style="font-family:'Courier New'">results</span>
                    folder. All canonical data can be found in the <span
                        style="font-family:'Courier New'">canonical_data</span> folder, and all corresponding results
                    can be found in the <span style="font-family:'Courier New'">canonical_results</span> folder.
                    Please note that the static data, static results, canonical data, and canonical results are a total
                    of about 16 GB.
                </p>
            </div>
        </div> -->

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Dynamic Data Examples
                </h3>
                <p>Note: these videos have sound</p>
                <span style="display: flex; flex-wrap: wrap;">
                    <div style="width: 365px; margin: 5px; text-align: center;">
                        <video controls autoplay loop muted style="width: 100%;">
                            <source
                                src="https://github.com/diva360/diva360.github.io/raw/main/DiVA/images/put_fruit_data.mov">
                        </video>
                        <p>Put Fruit Data</p>
                    </div>
                    <div style="width: 365px; margin: 5px; text-align: center;">
                        <video controls autoplay loop muted style="width: 100%;">
                            <source
                                src="https://github.com/diva360/diva360.github.io/raw/main/DiVA/images/penguin_data.mov">
                        </video>
                        <p>Penguin Data</p>
                    </div>
                </span>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Dynamic Baseline Examples
                </h3>
                <p>Note: these videos have sound</p>
                <span style="display: flex; flex-wrap: wrap;">
                    <div style="width: 365px; margin: 5px; text-align: center;">
                        <video controls autoplay loop muted style="width: 100%;">
                            <source
                                src="https://github.com/diva360/diva360.github.io/raw/main/DiVA/images/put_fruit_result.mov">
                        </video>
                        <p>Put Fruit Per Frame Instant NGP</p>
                    </div>
                    <div style="width: 365px; margin: 5px; text-align: center;">
                        <video controls autoplay loop muted style="width: 100%;">
                            <source
                                src="https://github.com/diva360/diva360.github.io/raw/main/DiVA/images/penguin_results.mov">
                        </video>
                        <p>Penguin Per Frame Instant NGP</p>
                    </div>
                </span>

                <h4>Comparison Between Instant NGP and Mixvoxels</h4>
                <p>Note: these videos have sound</p>
                <span style="display: flex; flex-wrap: wrap;">
                    <div style="width: 365px; margin: 5px; text-align: center;">
                        <video controls autoplay loop muted style="width: 100%;">
                            <source
                                src="https://github.com/diva360/diva360.github.io/raw/main/DiVA/images/wolf_ingp.mov">
                        </video>
                        <p>Wolf Per Frame Instant NGP</p>
                    </div>
                    <div style="width: 365px; margin: 5px; text-align: center;">
                        <video controls autoplay loop muted style="width: 100%;">
                            <source
                                src="https://github.com/diva360/diva360.github.io/raw/main/DiVA/images/wolf_mixvoxels.mov">
                        </video>
                        <p>Wolf Mixvoxels</p>
                    </div>
                </span>
                <span style="display: flex; flex-wrap: wrap;">
                    <div style="width: 365px; margin: 5px; text-align: center;">
                        <video controls autoplay loop muted style="width: 365px; margin: 5px;">
                            <source
                                src="https://github.com/diva360/diva360.github.io/raw/main/DiVA/images/xylophone_ingp.mov">
                        </video>
                        <p>Xylophone Per Frame Instant NGP</p>
                    </div>
                    <div style="width: 365px; margin: 5px; text-align: center;">
                        <video controls autoplay loop muted style="width: 365px; margin: 5px;">
                            <source
                                src="https://github.com/diva360/diva360.github.io/raw/main/DiVA/images/xylophone_mixvoxels.mov">
                        </video>
                        <p>Xylophone Mixvoxels</p>
                    </div>
                </span>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Static Data Examples
                </h3>
                <p>Note: only 48/53 cameras are shown</p>
                <span style="display: flex; flex-wrap: wrap;">
                    <div style="width: 365px; margin: 5px; text-align: center;">
                        <img src="./DiVA/images/car00_random_collage.png" width="100%">
                        <p>car00_random data</p>
                    </div>
                    <div style="width: 365px; margin: 5px; text-align: center;">
                        <img src="./DiVA/images/fruit00_random_collage.png" width="100%">
                        <p>fruit00_random data</p>
                    </div>
                </span>
                <span style="display: flex; flex-wrap: wrap;">
                    <div style="width: 365px; margin: 5px; text-align: center;">
                        <img src="./DiVA/images/scene00_clean_collage.png" width="100%">
                        <p>scene00_clean data</p>
                    </div>
                    <div style="width: 365px; margin: 5px; text-align: center;">
                        <img src="./DiVA/images/scene00_messy2_collage.png" width="100%">
                        <p>scene00_messy2 data</p>
                    </div>
                </span>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Static Baseline Examples
                </h3>
                <span style="display: flex; flex-wrap: wrap;">
                    <div style="width: 365px; margin: 5px; text-align: center;">
                        <video controls autoplay loop muted style="width: 100%;">
                            <source
                                src="https://github.com/diva360/diva360.github.io/raw/main/DiVA/images/car00_random.mov">
                        </video>
                        <p>car00_random Instant NGP</p>
                    </div>
                    <div style="width: 365px; margin: 5px; text-align: center;">
                        <video controls autoplay loop muted style="width: 100%;">
                            <source
                                src="https://github.com/diva360/diva360.github.io/raw/main/DiVA/images/fruit00_random.mov">
                        </video>
                        <p>fruit00_random Instant NGP</p>
                    </div>
                </span>
                <span style="display: flex; flex-wrap: wrap;">
                    <div style="width: 365px; margin: 5px; text-align: center;">
                        <video controls autoplay loop muted style="width: 100%;">
                            <source
                                src="https://github.com/diva360/diva360.github.io/raw/main/DiVA/images/scene00_clean.mov">
                        </video>
                        <p>scene00_clean Instant NGP</p>
                    </div>
                    <div style="width: 365px; margin: 5px; text-align: center;">
                        <video controls autoplay loop muted style="width: 100%;">
                            <source
                                src="https://github.com/diva360/diva360.github.io/raw/main/DiVA/images/scene00_messy2.mov">
                        </video>
                        <p>scene00_messy2 Instant NGP</p>
                    </div>
                </span>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                The website template was borrowed from <a href="http://mgharbi.com/" target=”_blank”>Michaël Gharbi</a>.
                <p></p>
            </div>
        </div>

</body>

</html>